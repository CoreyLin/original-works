# Hyperledger Fabric中的持久化、备份和灾难恢复

你需要为orderer和peer的docker容器的目录/var/hyperledger/production挂载一个卷。这是保存所有包含通道信息、交易和区块的持久化数据的地方。

如果你通过docker-compose运行容器，你可以添加:

	volumes:
	  - <some local dir>:/var/hyperledger/production
	  
如果你通过docker run运行容器，请添加参数:

	-v <some local dir>:/var/hyperledger/production
	
你还需要确保每个节点都指向自己的目录，这样才不会发生冲突。

https://stackoverflow.com/questions/50420225/hyperledger-data-persistence-between-fabric-restarts

---

将数据映射到主机

for each zk:

volumes:

	/var/hyperledger/zk{number}/data:/data
	/var/hyperledger/zk{number}/datalog:/datalog
	
for each kafka:

volumes:

	/var/hyperledger/kafka{number}:/tmp/kafka-logs

for each orderer and peer:

volumes:

	/var/hyperledger/peer{number}/org{number}:/var/hyperledger/production

我使用couchdb来存储数据，所以我也将数据映射到主机

volumes:

	/var/hyperledger/couchdb{number}:/opt/couchdb/data
	
https://jira.hyperledger.org/browse/FAB-6120

---

Hyperledger Fabric中的备份和灾难恢复

Hyperledger Fabric提供了简单的机制来备份你的ledgerdata和Statedatabse (Couchdb)。其目的是将peer/orderer的存储卷的卷挂载到备份卷。peer和orderer存储都位于/var/hyperledger/production(默认位置)。如果我们能够将这些卷从容器挂载到本地主机，并使用相同的卷来构建网络，那么链码、通道和数据都将被持久化，保持不变。

示例：

	- /mybackuppath/orderer:/var/hyperledger/production
	
上面的行应该被包含在docker-composer的orderer volumes中。

如果你没有配置备份卷（backup volume）并且网络已经运行了一段时间了，应该怎么办?

你可以使用docker cp & path复制Orderer和Peer存储卷，对其备份。然后可以将备份路径添加到docker-compose.yml，这样网络启动之后就是持久化的。

示例：

	docker cp myorderercontainerid:/var/hyperledger/production /mybackuppath/ordrererbackup
	
我们应该备份Couchdb(状态数据库)吗?

这是可选的，因为我们已经备份了ledgersdata, Peer将确保将数据从ledgersdata推送到它的状态数据库。

需要注意的是，在对couchdb进行备份时，要确保couchdb的记录（records）小于或等于ledgersdata，但不能超过ledgersdata，因为这会导致peer和状态数据库不同步。

https://medium.com/@rsripathi781/backup-disaster-recovery-in-hyperledger-fabric-ea9c7693d637

---

1. 如果一个peer宕机，然后又重新启动，那么它要么从orderer、自己组织中的另一个peer，要么可能从另一个组织中的一个peer，获得它丢失的区块。所有这些都取决于你如何配置gossip和锚peers。

2. 你的意思是，如果一个peer宕机或丢失了整个账本数据，它可以在稍后重新启动时从orderer那里获得整个账本数据吗?根据我对fabric的旧知识，orderer不会存储一个账本的所有区块数据。

3. 在当前的代码库中，不支持修剪/归档peer或orderer的账本。因此orderer节点将在其账本中拥有所有“区块”的一个完整副本，因此一个peer总是可以从orderer同步。将来，当修剪/存档/状态快照实现时，peers将需要为orderer没有的任何区块从其他peer(s)发起一个状态传输。

https://lists.hyperledger.org/g/fabric/topic/about_ledger_file_location/17549545?p=,,,20,0,0,0::recentpostdate%2Fsticky,,,20,2,580,17549545

---

Hyperledger区块链的数据存储在/var/hyperledger/production/db文件夹中

https://www.edureka.co/community/8928/where-does-hyperledger-fabric-store-database-the-blockchain

---

实际查看zookeeper的持久化数据

	[yzapps@00VMTL-FabricPeer-172-19-102-62 yingzi]$ docker exec -it zookeeper0.yingzi.com bash
	root@2713d49a9f76:/zookeeper-3.4.9# ll /data
	total 4
	drwxr-xr-x. 3 zookeeper zookeeper 35 May  5 03:00 ./
	drwxr-xr-x. 1 root      root      41 May  5 03:00 ../
	-rw-r--r--. 1 zookeeper zookeeper  2 May  5 03:00 myid
	drwxr-xr-x. 2 zookeeper zookeeper 65 May  5 03:00 version-2/
	root@2713d49a9f76:/zookeeper-3.4.9# ll /datalog
	total 0
	drwxr-xr-x. 3 zookeeper zookeeper 23 May  5 03:00 ./
	drwxr-xr-x. 1 root      root      41 May  5 03:00 ../
	drwxr-xr-x. 2 zookeeper zookeeper 27 May  5 03:01 version-2/
	root@2713d49a9f76:/zookeeper-3.4.9#

实际查看kafka的持久化数据

	[yzapps@00VMTL-FabricPeer-172-19-102-62 yingzi]$ docker exec -it kafka0.yingzi.com bash
	root@c2d8f3bf0396:/# ll /tmp/kafka-logs
	total 20
	drwxr-xr-x. 4 root root  238 May 19 06:22 ./
	drwxrwxrwt. 1 root root   47 May  5 03:01 ../
	-rw-r--r--. 1 root root    0 May  5 03:01 .lock
	-rw-r--r--. 1 root root    0 May  5 03:01 cleaner-offset-checkpoint
	-rw-r--r--. 1 root root    4 May 19 06:22 log-start-offset-checkpoint
	-rw-r--r--. 1 root root   54 May  5 03:01 meta.properties
	drwxr-xr-x. 2 root root 4096 May 13 01:37 mychannel-0/
	drwxr-xr-x. 2 root root  141 May  5 03:23 orderer-system-channel-0/
	-rw-r--r--. 1 root root   46 May 19 06:22 recovery-point-offset-checkpoint
	-rw-r--r--. 1 root root   46 May 19 06:22 replication-offset-checkpoint
	root@c2d8f3bf0396:/#

实际查看peer的持久化数据

	[yzapps@00VMTL-FabricPeer-172-19-102-62 yingzi]$ docker exec -it peer0.org1.yingzi.com bash
	root@42962c30ef51:/opt/gopath/src/github.com/hyperledger/fabric/peer# ll /var/hyperledger/production/
	total 0
	drwxr-xr-x. 1 root root  65 May  8 05:32 ./
	drwxr-xr-x. 1 root root  24 Jan  9 18:46 ../
	drwxr-xr-x. 2 root root  22 May  8 05:36 chaincodes/
	drwxr-xr-x. 8 root root 123 May  8 02:28 ledgersData/
	drwxr-xr-x. 2 root root  85 May  8 05:32 transientStore/
	root@42962c30ef51:/opt/gopath/src/github.com/hyperledger/fabric/peer#
	root@42962c30ef51:/opt/gopath/src/github.com/hyperledger/fabric/peer# ll /var/hyperledger/production/chaincodes/
	total 4
	drwxr-xr-x. 2 root root   22 May  8 05:36 ./
	drwxr-xr-x. 1 root root   65 May  8 05:32 ../
	-rw-r--r--. 1 root root 1894 May  8 05:36 mycc.1.0
	root@42962c30ef51:/opt/gopath/src/github.com/hyperledger/fabric/peer# ll /var/hyperledger/production/ledgersData/
	total 0
	drwxr-xr-x. 8 root root 123 May  8 02:28 ./
	drwxr-xr-x. 1 root root  65 May  8 05:32 ../
	drwxr-xr-x. 2 root root  85 May  8 02:28 bookkeeper/
	drwxr-xr-x. 4 root root  33 May  8 05:32 chains/
	drwxr-xr-x. 2 root root  85 May  8 02:28 configHistory/
	drwxr-xr-x. 2 root root  85 May  8 02:28 historyLeveldb/
	drwxr-xr-x. 2 root root  85 May  8 02:28 ledgerProvider/
	drwxr-xr-x. 2 root root  85 May  8 02:28 pvtdataStore/
	root@42962c30ef51:/opt/gopath/src/github.com/hyperledger/fabric/peer# ll /var/hyperledger/production/transientStore/
	total 12
	drwxr-xr-x. 2 root root  85 May  8 05:32 ./
	drwxr-xr-x. 1 root root  65 May  8 05:32 ../
	-rw-r--r--. 1 root root   0 May  8 05:32 000001.log
	-rw-r--r--. 1 root root  16 May  8 05:32 CURRENT
	-rw-r--r--. 1 root root   0 May  8 05:32 LOCK
	-rw-r--r--. 1 root root 358 May  8 05:32 LOG
	-rw-r--r--. 1 root root  54 May  8 05:32 MANIFEST-000000
	root@42962c30ef51:/opt/gopath/src/github.com/hyperledger/fabric/peer#
	
实际查看orderer的持久化数据
	
	[yzapps@00VMTL-FabricPeer-172-19-102-62 yingzi]$ docker exec -it orderer0.yingzi.com bash
	root@9255ad7d3a5e:/opt/gopath/src/github.com/hyperledger/fabric# ll /var/hyperledger/production/
	total 0
	drwxr-xr-x. 1 root root 21 May  5 03:23 ./
	drwxr-xr-x. 1 root root 39 May  5 03:23 ../
	drwxr-xr-x. 4 root root 33 May  5 03:23 orderer/
	root@9255ad7d3a5e:/opt/gopath/src/github.com/hyperledger/fabric# ll /var/hyperledger/production/orderer/
	total 0
	drwxr-xr-x. 4 root root 33 May  5 03:23 ./
	drwxr-xr-x. 1 root root 21 May  5 03:23 ../
	drwxr-xr-x. 4 root root 53 May  5 05:42 chains/
	drwxr-xr-x. 2 root root 85 May  5 03:23 index/
	root@9255ad7d3a5e:/opt/gopath/src/github.com/hyperledger/fabric# ll /var/hyperledger/production/orderer/chains
	total 0
	drwxr-xr-x. 4 root root 53 May  5 05:42 ./
	drwxr-xr-x. 4 root root 33 May  5 03:23 ../
	drwxr-xr-x. 2 root root 30 May  5 05:42 mychannel/
	drwxr-xr-x. 2 root root 30 May  5 03:23 orderer-system-channel/
	root@9255ad7d3a5e:/opt/gopath/src/github.com/hyperledger/fabric# ll /var/hyperledger/production/orderer/index/
	total 16
	drwxr-xr-x. 2 root root   85 May  5 03:23 ./
	drwxr-xr-x. 4 root root   33 May  5 03:23 ../
	-rw-r--r--. 1 root root 2093 May 13 01:37 000001.log
	-rw-r--r--. 1 root root   16 May  5 03:23 CURRENT
	-rw-r--r--. 1 root root    0 May  5 03:23 LOCK
	-rw-r--r--. 1 root root  358 May  5 03:23 LOG
	-rw-r--r--. 1 root root   54 May  5 03:23 MANIFEST-000000
	root@9255ad7d3a5e:/opt/gopath/src/github.com/hyperledger/fabric#
	
---

## 备份&恢复实践

### 1.不挂载volume，启动zk，kafka，orderer，peer，cli，并且安装、实例化链码

运行时数据并没有持久化到本地，如果把容器删掉，那么数据就丢失了

### 2.通过docker cp命令把容器中的数据拷贝到本地

	docker cp zookeeper0.yingzi.com:/data /home/yzapps/hyperledger/fabric-samples/yingzi/backup/zookeeper0.yingzi.com/data
	docker cp zookeeper0.yingzi.com:/datalog /home/yzapps/hyperledger/fabric-samples/yingzi/backup/zookeeper0.yingzi.com/datalog
	
	docker cp kafka0.yingzi.com:/tmp/kafka-logs /home/yzapps/hyperledger/fabric-samples/yingzi/backup/kafka0.yingzi.com/tmp/kafka-logs
	
	docker cp orderer0.yingzi.com:/var/hyperledger/production /home/yzapps/hyperledger/fabric-samples/yingzi/backup/orderer0.yingzi.com/var/hyperledger/production
	
	docker cp peer0.org1.yingzi.com:/var/hyperledger/production /home/yzapps/hyperledger/fabric-samples/yingzi/backup/peer0.org1.yingzi.com/var/hyperledger/production
	
注意：不需要把couchdb容器的数据拷贝到本地，因为couchdb的数据是世界状态，后续可以通过区块链账本数据自动生成。

### 3.通过docker-compose -f *** down把所有的容器全部remove

除此之外，还要用docker rm把链码的容器remove掉

### 4.在zk，kafka，orderer，peer的docker-compose yaml文件里加上数据挂载卷

zk:

    volumes:
        - /home/yzapps/hyperledger/fabric-samples/yingzi/backup/zookeeper0.yingzi.com/data:/data
        - /home/yzapps/hyperledger/fabric-samples/yingzi/backup/zookeeper0.yingzi.com/datalog:/datalog
		
kafka:

    volumes:
        - /home/yzapps/hyperledger/fabric-samples/yingzi/backup/kafka0.yingzi.com/tmp/kafka-logs:/tmp/kafka-logs
		
orderer:

    volumes:
		- /home/yzapps/hyperledger/fabric-samples/yingzi/backup/orderer0.yingzi.com/var/hyperledger/production:/var/hyperledger/production
		
peer:

    volumes:
        - /home/yzapps/hyperledger/fabric-samples/yingzi/backup/peer0.org1.yingzi.com/var/hyperledger/production:/var/hyperledger/production

### 5.重新启动zk，kafka，orderer，peer，cli

用docker-compose -f *** up -d命令重新启动zk，kafka，orderer，peer，cli容器

启动之后，链码容器暂时不会自动启动。

### 6.启动链码容器

在安装了链码的peer的cli上，调用链码的函数，比如peer chaincode query -C mychannel -n mycc -c '{"Args":["query","a"]}'

在peer0.org1 cli上调用之后，链码容器dev-peer0.org1.yingzi.com-mycc-1.0就会自动被生成。

在peer0.org2 cli上调用之后，链码容器dev-peer0.org2.yingzi.com-mycc-1.0就会自动被生成。

调用结果也是成功的，返回了备份前a的值，所以证明了备份恢复操作是成功的。
